{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file):\n",
    "    #Extract the data you want from file\n",
    "    altitude_lh = file.altitude_lh.data\n",
    "    surf_rain = file.surf_rain.data\n",
    "    latent_heating = file.latent_heating.data\n",
    "\n",
    "    lat = file.latitude.data\n",
    "    lon = file.longitude.data\n",
    "    time = file.time.data\n",
    "    \n",
    "    #create grid of altitude, lat, and lon coordinates\n",
    "    LAT, ALTITUDE, LON = np.meshgrid(lat, altitude_lh, lon)\n",
    "\n",
    "    #size of lat and lon as variables\n",
    "    nlat = len(lat)\n",
    "    nlon = len(lon)\n",
    "    nalt = len(altitude_lh)\n",
    "\n",
    "    #reshape as column vector (note the indicing is now column*ncolumns+row)\n",
    "    surf_rain = np.reshape(surf_rain,[nlat*nlon])\n",
    "    LH = np.reshape(latent_heating,[nalt,nlat*nlon])\n",
    "    ALTITUDE = np.reshape (ALTITUDE,[nalt,nlat*nlon])\n",
    "    LON = np.reshape (LON,[nalt,nlat*nlon])\n",
    "    LAT = np.reshape (LAT,[nalt,nlat*nlon])\n",
    "\n",
    "    #Remove values with NaN and zero rainfall\n",
    "    surf_R = surf_rain[~np.isnan(surf_rain)]\n",
    "    surf_r = surf_R[np.nonzero(surf_R)]\n",
    "\n",
    "    Lat_Heat = LH[:,~np.isnan(surf_rain)]\n",
    "    Lat_Heat = Lat_Heat[:,np.nonzero(surf_R)]\n",
    "    Lat_Heat = np.squeeze(Lat_Heat)\n",
    "\n",
    "    ALTITUDE = ALTITUDE[:,~np.isnan(surf_rain)]\n",
    "    ALTITUDE = ALTITUDE[:,np.nonzero(surf_R)]\n",
    "    ALTITUDE = np.squeeze(ALTITUDE)\n",
    "\n",
    "    LAT = LAT[:,~np.isnan(surf_rain)]\n",
    "    LAT = LAT[:,np.nonzero(surf_R)]\n",
    "    LAT = np.squeeze(LAT)\n",
    "\n",
    "    LON = LON[:,~np.isnan(surf_rain)]\n",
    "    LON = LON[:,np.nonzero(surf_R)]\n",
    "    LON = np.squeeze(LON)\n",
    "\n",
    "    #Remove any profiles where there is missing latent heat info\n",
    "    surf_r = surf_r[~pd.isnull(Lat_Heat).any(axis=0)]\n",
    "    LAT = LAT[:,~pd.isnull(Lat_Heat).any(axis=0)]\n",
    "    LON = LON[:,~pd.isnull(Lat_Heat).any(axis=0)]\n",
    "    ALTITUDE = ALTITUDE[:,~pd.isnull(Lat_Heat).any(axis=0)]\n",
    "    Lat_Heat = Lat_Heat[:,~pd.isnull(Lat_Heat).any(axis=0)]\n",
    "    Time = np.repeat(time,len(surf_r))\n",
    "    \n",
    "    return Lat_Heat.T, surf_r.T, ALTITUDE.T, LAT.T, LON.T, Time.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##months = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "for m in range(len(months)):\n",
    "    Lat_Heat = []\n",
    "    surf_r = []\n",
    "    ALTITUDE = []\n",
    "    LAT = []\n",
    "    LON = []\n",
    "    TIME = []\n",
    "    count = 0\n",
    "    for file in glob.glob(\"/Users/Lauren/Documents/NOAA/Precipitation/**/\"+months[m]+\"/*.nc4\", recursive=True):\n",
    "        L, S, A, la, lo, Ti = extract_data(xr.open_dataset(file))\n",
    "        if count==0:\n",
    "            Lat_Heat = L\n",
    "            ALTITUDE = A\n",
    "            LAT = la\n",
    "            LON = lo\n",
    "            TIME = Ti\n",
    "            count += 1\n",
    "            print(Lat_Heat.shape)\n",
    "        else:\n",
    "            Lat_Heat = np.concatenate((Lat_Heat,L),axis =0)\n",
    "            ALTITUDE = np.concatenate((ALTITUDE,A),axis =0)\n",
    "            LAT = np.concatenate((LAT,la),axis =0)\n",
    "            LON = np.concatenate((LON,lo),axis =0)\n",
    "            TIME = np.concatenate((TIME,Ti),axis =0)\n",
    "        surf_r = np.append(surf_r,S)\n",
    "    test = xr.Dataset(\n",
    "        data_vars = {'Latitude': (('time', 'altitude'),LAT), \n",
    "                     'Longitude': (('time', 'altitude'),LON), \n",
    "                     'Latent_Heat': (('time', 'altitude'), Lat_Heat),\n",
    "                     'surface_rain': (('time'), surf_r)},\n",
    "        coords = {'time': TIME,\n",
    "                 'altitude': ALTITUDE[0,:]})\n",
    "    print(test)\n",
    "    test.to_netcdf(path = \"EPO_1998_\"+months[m]+\".nc4\", compute = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LH = []\n",
    "SR = []\n",
    "Longitude = []\n",
    "Latitude = []\n",
    "count = 1\n",
    "for file in glob.glob(\"/Users/Lauren/Documents/NOAA/Precipitation/*.nc4\"):\n",
    "    ds = xr.open_dataset(file)\n",
    "    if count==1: \n",
    "        LH = ds.Latent_Heat.data\n",
    "        count +=1\n",
    "    else:\n",
    "        LH = np.concatenate((LH,ds.Latent_Heat.data),axis=0)\n",
    "    SR = np.append(SR,ds.surface_rain.data)\n",
    "    Latitude = np.append(Latitude,ds.Latitude.data[:,1])\n",
    "    Longitude = np.append(Longitude,ds.Longitude.data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the latent heat and rain rate at surface together for trainin data\n",
    "Xdata = np.concatenate((LH,SR.reshape(len(SR),1)),axis = 1)\n",
    "Xdata = Xdata[np.where(SR>5),:]\n",
    "Xdata = np.squeeze(Xdata)\n",
    "\n",
    "#divide by standard deviation to avoid one metric pulling harder than others\n",
    "MIN = np.min(Xdata,axis=0)\n",
    "MAX = np.max(Xdata,axis=0)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "Xdata_scaled = np.subtract(Xdata,MIN)\n",
    "Xdata_scaled = np.divide(Xdata_scaled,MAX-MIN)\n",
    "#Xdata_scaled[np.isnan(Xdata_scaled)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DBSCAN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-87574e8514c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#model = KMeans(n_clusters=3, random_state=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(centers.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdata_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DBSCAN' is not defined"
     ]
    }
   ],
   "source": [
    "model = DBSCAN(eps=.05, min_samples=100)\n",
    "#model = KMeans(n_clusters=3, random_state=0)\n",
    "#print(centers.shape)\n",
    "model.fit(Xdata_scaled[0:100000,:])\n",
    "\n",
    "#centers = model.cluster_centers_\n",
    "labels = model.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(n_clusters_)\n",
    "print('Done')\n",
    "\n",
    "#plt.pcolormesh(centers[:,0:-1]*SDEV[None,0:-1])\n",
    "#plt.colorbar(orientation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xdata_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c8dc4a36f3d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXdata_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcat0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xdata_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "test = Xdata_scaled[0:100000,:] \n",
    "cat0 = np.mean(test[labels==0,:],axis=0)\n",
    "cat1 = np.mean(test[labels==1,:],axis=0)\n",
    "cat2 = np.mean(test[labels==2,:],axis=0)\n",
    "\n",
    "print(test[labels==-1,:].shape)\n",
    "#print(test[labels==1,:].shape)\n",
    "print(test[labels==0,:].shape)\n",
    "\n",
    "plt.plot(test[labels==-1,:].T)\n",
    "\n",
    "\n",
    "#plt.plot(cat0)\n",
    "#plt.plot(cat1)\n",
    "#plt.plot(cat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels = model.labels_\n",
    "d = {'lat': Latitude, 'lon': Longitude, 'label': labels}\n",
    "d = pd.DataFrame(data=d)\n",
    "df = d.groupby(d.columns.tolist(),as_index=False).size()\n",
    "axes = np.array(df.axes)\n",
    "values = np.array(df.values)\n",
    "print(np.array(df.axes))\n",
    "print(np.array(df.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "lats = axes[:,:,0]\n",
    "lons = axes[:,:,1]\n",
    "cate = axes[:,:,2]\n",
    "\n",
    "\n",
    "# How much to zoom from coordinates (in degrees)\n",
    "zoom_scale = 3\n",
    "\n",
    "# Setup the bounding box for the zoom and bounds of the map\n",
    "bbox = [np.min(lats)-zoom_scale,np.max(lats)+zoom_scale,\\\n",
    "        np.min(lons)-zoom_scale,np.max(lons)+zoom_scale]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "# Define the projection, scale, the corners of the map, and the resolution.\n",
    "m = Basemap(projection='merc',llcrnrlat=bbox[0],urcrnrlat=bbox[1],\\\n",
    "            llcrnrlon=bbox[2],urcrnrlon=bbox[3],lat_ts=10,resolution='i')\n",
    "\n",
    "# Draw coastlines and fill continents and water with color\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents(color='#CCCCCC',lake_color='lightblue')\n",
    "\n",
    "# draw parallels, meridians, and color boundaries\n",
    "m.drawparallels(np.arange(bbox[0],bbox[1],(bbox[1]-bbox[0])/5),labels=[1,0,0,0])\n",
    "m.drawmeridians(np.arange(bbox[2],bbox[3],(bbox[3]-bbox[2])/5),labels=[0,0,0,1],rotation=15)\n",
    "m.drawmapboundary(fill_color='lightblue')\n",
    "\n",
    "# format colors for elevation range\n",
    "alt_min = np.min(values)\n",
    "alt_max = np.max(values)\n",
    "cmap = plt.get_cmap('gist_earth')\n",
    "normalize = matplotlib.colors.Normalize(vmin=alt_min, vmax=alt_max)\n",
    "\n",
    "# plot elevations with different colors using the numpy interpolation mapping tool\n",
    "# the range [50,200] can be changed to create different colors and ranges\n",
    "for ii in range(0,len(values)):\n",
    "    x,y = m(lons[ii],lats[ii])\n",
    "    color_interp = np.interp(values[ii],[alt_min,alt_max],[50,200])\n",
    "    plt.plot(x,y,3,marker='o',color=cmap(int(color_interp)))\n",
    "\n",
    "# format the colorbar \n",
    "cax, _ = matplotlib.colorbar.make_axes(ax)\n",
    "cbar = matplotlib.colorbar.ColorbarBase(cax, cmap=cmap,norm=normalize,label='Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12550147392335598\n"
     ]
    }
   ],
   "source": [
    "test = SR[np.where(SR>5)]\n",
    "xdata = Xdata[np.where(SR>5),:]\n",
    "print(len(test)/len(SR))\n",
    "#plt.hist(SR, bins='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
